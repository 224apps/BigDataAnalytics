{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(text, file_path):\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(\"\\n\\n\".join(text))\n",
    "        print(\"Text has been written to the file successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dictionary_to_file(data, file_path):\n",
    "    try:\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "            print(\"Text has been written to the file successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data_from(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    bio_urls = {}\n",
    "    courses_taught = {}\n",
    "    bios = {}\n",
    "    names = []\n",
    "    \n",
    "    # Find all elements with the specified class\n",
    "    all_entries = soup.find_all(\"div\", class_=\"col-sm-10\")\n",
    "\n",
    "    for entry in all_entries:\n",
    "        # Find the anchor element within the div with the class \"directory-name\"\n",
    "        anchor_element = entry.find(\"div\", class_=\"directory-name\").find(\"a\")\n",
    "\n",
    "        # Extract the bio URL from the 'href' attribute of the anchor element\n",
    "        if anchor_element:\n",
    "            bio_url = anchor_element.get(\"href\")\n",
    "            \n",
    "            # Check if the URL contains the desired substrings\n",
    "            if \"http://homes.cs.washington.edu/\" in bio_url or \"https://www.cs.washington.edu/people/faculty\" in bio_url:\n",
    "                # Now, let's scrape data from the bio URL\n",
    "                bio_page = requests.get(bio_url)\n",
    "                bio_soup = BeautifulSoup(bio_page.content, 'html.parser')\n",
    "                name = bio_soup.title.text.strip().split(\"|\")[0] if bio_soup.title else \"No Name\"\n",
    "                bio_urls[name] = bio_url\n",
    " \n",
    "                # Extract the content under the \"Teaching\" section (if available)\n",
    "                teaching_header = bio_soup.find(\"h3\", text=\"Teaching\")\n",
    "                if teaching_header:\n",
    "                    courses_names = []\n",
    "                    teaching_content_element = teaching_header.find_next_sibling(\"table\", class_=\"table teaching\")\n",
    "                    if teaching_content_element:\n",
    "                        # Find all rows in the table body\n",
    "                        rows = teaching_content_element.find_all(\"tr\")\n",
    "                        course_quarters = []\n",
    "                        for row in rows[1:]:\n",
    "                            # Get the course name and quarters\n",
    "                            cols = row.find_all(\"th\")\n",
    "                            course_name = cols[0].text.strip()[:]\n",
    "                            print(course_name)\n",
    "                            courses_names.append(course_name)\n",
    "                    else:\n",
    "                        courses_names.append(\"Teaching content not found.\")\n",
    "                        \n",
    "                    courses_taught[name] = courses_names\n",
    "\n",
    "                else:\n",
    "                    courses_taught[name] = []\n",
    "\n",
    "                # Extract the biography content from the biography URL\n",
    "                biography_header = bio_soup.find('div', class_='field-item')\n",
    "                if biography_header:\n",
    "                    # Find the next sibling after the <h3>Biography</h3> header\n",
    "                    biography_content_element = biography_header.find_next_sibling(\"p\")\n",
    "                  \n",
    "                    if biography_content_element:\n",
    "                        # Get the biography text\n",
    "                        biography_text = biography_content_element.text.strip()\n",
    "                        bios[name] = biography_text\n",
    "                    else:\n",
    "                        bios[name] = \"Biography content not found.\"\n",
    "                else:\n",
    "                    bios[name] = \"Biography section not found.\"\n",
    "            \n",
    "    \n",
    "    return bio_urls, courses_taught, bios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSE 332: Data Structures & Parallelism\n",
      "CSE 391: System and Software Tools\n",
      "CSE 160: Data Programming\n",
      "CSE 351: The Hardware/Software Interface\n",
      "CSE General TA Training\n",
      "CSE 590E: Computer Science Education Seminar\n",
      "{'Richard Anderson ': 'https://www.cs.washington.edu/people/faculty/anderson/', 'Ruth Anderson': 'http://homes.cs.washington.edu/~rea', 'Yejin Choi': 'http://homes.cs.washington.edu/~yejin/', 'Dieter Fox ': 'http://homes.cs.washington.edu/~fox', 'Dan Grossman': 'http://homes.cs.washington.edu/~djg/', 'Jeffrey Heer': 'http://homes.cs.washington.edu/~jheer/', 'Justin Hsia': 'http://homes.cs.washington.edu/~jhsia/', 'Tadayoshi Kohno (aka Yoshi Kohno)': 'http://homes.cs.washington.edu/~yoshi/', \"Shayan Oveis Gharan's homepage\": 'http://homes.cs.washington.edu/~shayan/', 'Anup Rao ': 'https://www.cs.washington.edu/people/faculty/anuprao/', 'No Name': 'http://homes.cs.washington.edu/~seitz/', 'Linda Shapiro': 'http://homes.cs.washington.edu/~shapiro/', 'Joshua Smith ': 'https://www.cs.washington.edu/people/faculty/jrs/', 'Stefano Tessaro': 'http://homes.cs.washington.edu/~tessaro/', 'Emina Torlak': 'http://homes.cs.washington.edu/~emina/', 'James R. Wilcox': 'http://homes.cs.washington.edu/~jrw12/'}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.cs.washington.edu/people/faculty\"\n",
    "bio_urls, courses_taught, bios = scrape_data_from(url)\n",
    "print(bio_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text has been written to the file successfully.\n",
      "Text has been written to the file successfully.\n",
      "Text has been written to the file successfully.\n"
     ]
    }
   ],
   "source": [
    "#save the result into the files\n",
    "save_dictionary_to_file(bio_urls, 'bio_urls.txt')\n",
    "save_dictionary_to_file(courses_taught, 'courses_taught.txt')\n",
    "save_dictionary_to_file(bios, 'bios.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
